#!/bin/bash
#
# BigLinux Store 
# www.biglinux.com.br
# By Bruno Gonçalves
# 11/01/2020
# License: GPL v2 or greater

#Translation
export TEXTDOMAINDIR="/usr/share/locale"
export TEXTDOMAIN=big-store

# Folder to save list os packages
## portuguese
# Seleciona e cria a pasta para salvar os arquivos para cache da busca
FOLDER_TO_SAVE_FILES="$HOME/.bigstore/snap_list_files/snap_list"
FILE_TO_SAVE_CACHE="$HOME/.bigstore/snap.cache"

rm -R ~/.bigstore/snap_list_files/
mkdir -p ~/.bigstore/snap_list_files/

# Anotation with all parameters in API
## portuguese
# Anotação com as opções possíveis para utilizar na API
#https://api.snapcraft.io/api/v1/snaps/search?confinement=strict,classic&fields=anon_download_url,architecture,channel,download_sha3_384,summary,description,binary_filesize,download_url,last_updated,package_name,prices,publisher,ratings_average,revision,snap_id,license,base,media,support_url,contact,title,content,version,origin,developer_id,developer_name,developer_validation,private,confinement,common_ids&q=office&scope=wide:

# Anotation with search wps-2019-snap in cache
## portuguese
# Anotação com a busca por wps-2019-snap em cache
# jq -r '._embedded."clickindex:package"[]| select( .package_name == "wps-2019-snap" )' $FOLDER_TO_SAVE_FILES*


# Download first page with applications in snap site
## portuguese
# Faz o download da página inicial
curl "https://api.snapcraft.io/api/v1/snaps/search?confinement=strict&fields=architecture,summary,description,package_name,snap_id,title,content,version,common_ids,binary_filesize,license,developer_name,media,&scope=wide:" > ${FOLDER_TO_SAVE_FILES}

# Read total pages needed to download
## portuguese
# Le na pagina inicial quantas paginas devem ser baixadas e salva o valor na variavel $NUMBER_OF_PAGES
NUMBER_OF_PAGES="$(jq -r '._links.last' ${FOLDER_TO_SAVE_FILES} | sed 's|.*page=||g;s|"||g' | grep [0-9])"

# Loop to download all pages
## portuguese
# Inicia o download em paralelo de todas as paginas
PAGE=2
while [  "$PAGE" -lt "$NUMBER_OF_PAGES" ]; do

    echo "Downloading $PAGE of $NUMBER_OF_PAGES"
        
    curl "https://api.snapcraft.io/api/v1/snaps/search?confinement=strict,classic&fields=architecture,summary,description,package_name,snap_id,title,content,version,common_ids,binary_filesize,license,developer_name,media,&scope=wide:&page=$PAGE" >> ${FOLDER_TO_SAVE_FILES}$PAGE &
    let PAGE=PAGE+1; 
done

# Waiting all downloads
## portuguese
# Aguarda o download de todos os arquivos
wait

# Filtering files and make cache file to use in searching system
## portuguese
# Filtra o resultado dos arquivos e cria um arquivo de cache que será utilizado nas buscas
jq -r '._embedded."clickindex:package"[]| .title + "|" + .snap_id + "|" + .media[0].url + "|" + .summary + "|" + .version + "|" + .package_name + "|"' ${FOLDER_TO_SAVE_FILES}* | sort -u > $FILE_TO_SAVE_CACHE
